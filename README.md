# Simply Marcus
A simple web-based QA app using ollama to run local LLM inference.

# Quick Start
To be able to run this project you need to make sure that the ollama is serving and set the host to the appropriate address.
Also, you need to download the requirements like so:
```bash
pip install -r requirements.txt
```

To start the development server run on the project folder:
```bash
fastapi dev
```

Then open [localhost:8000](http://localhost:8000) and you are good to go!